{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35472,
     "status": "ok",
     "timestamp": 1588031342670,
     "user": {
      "displayName": "Igor Nikitin",
      "photoUrl": "",
      "userId": "06006776301613262626"
     },
     "user_tz": -60
    },
    "id": "e7R2X2YUzNPg",
    "outputId": "88b1384b-c6bc-48c6-91bb-164c16825ebb"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### REQUIREMENTS ###\n",
    "####################\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "from itertools import islice # For reading only a part of the data file\n",
    "from collections import OrderedDict # For defining a variable-length nn.Sequential()\n",
    "from collections import defaultdict # Used in readData()\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import math # For math.ceil() in readLine()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive/')\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABHoDZVsQ1F9"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "### CONTROL CONSTANTS ###\n",
    "#########################\n",
    "\n",
    "DS_SIZE = 1000\n",
    "LOAD_DATASET_FROM_FILE = True\n",
    "LOAD_MODEL_FROM_FILE = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "num_of_batch_files = 1\n",
    "CUDA_LAUNCH_BLOCKING = 1\n",
    "START_ITER = 0\n",
    "PATH = '.\\\\AML\\\\old\\\\'\n",
    "LOGGING = False\n",
    "LOG = open(PATH + 'log', 'w', encoding='utf-8')\n",
    "TEACHER_FORCING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-4R4p4ujHz4"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### DATA-PREPROCESSING ###\n",
    "##########################\n",
    "\n",
    "# ..._BATCH_SIZE is NOT the number of sentences in a batch! It's the size of the tensor (i.e. accounts for the character sequence length).\n",
    "MIN_BATCH_SIZE = 2400\n",
    "MAX_BATCH_SIZE = 3000\n",
    "BATCHES_PER_FILE = 100000\n",
    "\n",
    "SOS_token = '\\2'\n",
    "EOS_token = '\\3'\n",
    "PSC_token = '\\4' # Padding Sequence Character (increase the length of the encoder input sequence by 20% using PSC tokens)\n",
    "NAC_token = '\\5' # Not A Character (used for padding only, doesn't carry any meaning)\n",
    "UCF_token = '\\7' # Unknown Character Found (replace all unknown characters with this token)\n",
    "\n",
    "PAD_TO = 50 # The input and target (in training) sequences will be padded to the nearest multiple of PAD_TO for efficient batching.\n",
    "\n",
    "all_letters = SOS_token + EOS_token + UCF_token + PSC_token + NAC_token + string.printable + \"£€°\\u00E4\\u00EF\\u00F6\\u00FC\\u00DF\\u00C4\\u00CF\\u00D6\\u00DC\\u1E9E\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    html_subs = {'&quot;': '\"', '&apos;': '\\'', '&amp;': '&', '&#91;': '[', '&#93;': ']', '&lt;': '<',  '&gt;': '>', '&#124;': '|'}\n",
    "\n",
    "    # NFD = Combine characters that \"have the same meaning\"\n",
    "    # unicodedata.category(c) == 'Mn' <==> Unicode Non-spacing Mark\n",
    "    for sub in html_subs:\n",
    "        s = s.replace(sub, html_subs[sub])\n",
    "    s = s.replace(' ##AT##-##AT## ', '-').replace('\\n', '')\n",
    "\n",
    "    NFD =  [c for c in unicodedata.normalize('NFD', s)\n",
    "            if (unicodedata.category(c) != 'Mn' or c == '\\u0308')] # Leave the umlaut!!!\n",
    "\n",
    "    # But if the umlaut is not over 'a', 'o' or 'u', German doesn't have such a letter. Drop the umlaut.\n",
    "    NFD_filter_umlauts = [NFD[0]]\n",
    "    for i in range(1, len(NFD)):\n",
    "        if NFD[i] != '\\u0308' or NFD[i - 1] in 'AIOUaiou': \n",
    "            NFD_filter_umlauts.append(NFD[i])   \n",
    "\n",
    "    return unicodedata.normalize('NFC', ''.join([c if c in all_letters or c == '\\u0308'\n",
    "                    else UCF_token # Insert a UCF_token in place of c otherwise\n",
    "                    for c in NFD_filter_umlauts]))\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    assert all_letters.find(letter) != -1\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def readLine(line, type): \n",
    "    if type == 'enc':\n",
    "        tmp = unicodeToAscii(line.strip()) + PSC_token * int(0.2 * len(line)) + EOS_token\n",
    "    else:\n",
    "        tmp = unicodeToAscii(line.strip()) + EOS_token\n",
    "    tmp += NAC_token * (math.ceil(len(tmp) / PAD_TO) * PAD_TO - len(tmp))\n",
    "    return tmp\n",
    "\n",
    "# Turn a line into a <BATCH_SIZE x line_length x n_letters> array of letter indices.\n",
    "def bucketToBatch(bucket):\n",
    "    source_tensor = torch.zeros(len(bucket), len(bucket[0][0]), dtype=torch.int64, device=device)\n",
    "    target_tensor = torch.zeros(len(bucket), len(bucket[0][1]), dtype=torch.int64, device=device)\n",
    "    for i in range(len(bucket)):\n",
    "        for char_pos, char in enumerate(bucket[i][0]):\n",
    "            source_tensor[i][char_pos] = letterToIndex(char)\n",
    "        for char_pos, char in enumerate(bucket[i][1]):\n",
    "            target_tensor[i][char_pos] = letterToIndex(char)\n",
    "\n",
    "    return (source_tensor, target_tensor)\n",
    "\n",
    "def readData(prefix, lang1, lang2, N = None):\n",
    "    num_of_batch_files = 0\n",
    "    bucketised_batches = []\n",
    "\n",
    "    lines1 = open(PATH + '%s.%s' % (prefix, lang1), encoding='utf-8')\n",
    "    lines2 = open(PATH + '%s.%s' % (prefix, lang2), encoding='utf-8')\n",
    "\n",
    "    # Read in only the first N lines of the train files. N = None means reading the entire file.\n",
    "    bucketised_tensor_pairs = defaultdict(list)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for line1, line2 in islice(zip(lines1, lines2), N):\n",
    "        i += 1\n",
    "        if DS_SIZE >= 100 and i % ((DS_SIZE // 100) * 5) == 0:\n",
    "            print(\"%d%% of the datafile was read.\" % (i / (DS_SIZE // 100)))\n",
    "        tmp1 = readLine(line1, 'enc')\n",
    "        tmp2 = readLine(line2, 'dec')\n",
    "        cur_bucket = bucketised_tensor_pairs[(len(tmp1),len(tmp2))]\n",
    "        cur_bucket.append((tmp1, tmp2)) #.append((lineToTensor(tmp1), lineToTensor(tmp2)))\n",
    "        if len(cur_bucket) * max(len(tmp1), len(tmp2)) >= MAX_BATCH_SIZE:\n",
    "            bucketised_batches.append(bucketToBatch(cur_bucket))\n",
    "            del bucketised_tensor_pairs[(len(tmp1),len(tmp2))]\n",
    "            if len(bucketised_batches) >= BATCHES_PER_FILE:\n",
    "                torch.save(bucketised_batches, PATH + 'bucketised_batches_%d' % num_of_batch_files)\n",
    "                num_of_batch_files += 1\n",
    "                bucketised_batches = []\n",
    "\n",
    "    for key in bucketised_tensor_pairs.keys():\n",
    "        if len(bucketised_tensor_pairs[key]) * max(key[0], key[1]) >= MIN_BATCH_SIZE:\n",
    "            bucketised_batches.append(bucketToBatch(bucketised_tensor_pairs[key]))\n",
    "            if len(bucketised_batches) >= BATCHES_PER_FILE:\n",
    "                torch.save(bucketised_batches, PATH + 'bucketised_batches_%d' % num_of_batch_files)\n",
    "                num_of_batch_files += 1\n",
    "                bucketised_batches = []\n",
    "\n",
    "    if bucketised_batches:\n",
    "        torch.save(bucketised_batches, PATH + 'bucketised_batches_%d' % num_of_batch_files)\n",
    "        num_of_batch_files += 1\n",
    "\n",
    "    return num_of_batch_files\n",
    "\n",
    "if not LOAD_DATASET_FROM_FILE:\n",
    "    num_of_batch_files = readData('train', 'en','de', DS_SIZE)\n",
    "bucketised_batches = torch.load(PATH + '/bucketised_batches_0', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOqeJNfZxlBC"
   },
   "outputs": [],
   "source": [
    "########################\n",
    "### MODEL DEFINITION ###\n",
    "########################\n",
    "\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# CONVOLUTION PARAMETER DEFINITIONS\n",
    "\n",
    "# wdt = width; str = stride; pad = padding; dil = dilation\n",
    "conv1x1 = {'wdt': 1, 'str': 1, 'pad': 0, 'dil': 1}\n",
    "conv1xk = {'wdt': 3, 'str': 1, 'pad': 1} # Keep wdt odd and pad to (wdt+1)/2. On changing wdt MAKE SURE TO TEST masking in ResBlock::forward!!!\n",
    "\n",
    "\n",
    "\n",
    "# ENCODER & DECODER\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels, dilation, type):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.type =type\n",
    "        channel_factor = 2 if type != 'enc' else 1\n",
    "\n",
    "        # Note that the size of padding in conv1xk is chosen so that the size of the output of the block is equal to the size of the input.\n",
    "        # Be careful about changing the order! Assumed to be so in forward()!!!\n",
    "        self.resblock = nn.Sequential(OrderedDict([\n",
    "            #('norm_1', nn.InstanceNorm1d(channels)),                         # LayerNorm is computed along the last (i.e. the sequence) dimension.\n",
    "            ('relu_1', nn.ReLU()),\n",
    "            ('conv1x1_1', nn.Conv1d(channel_factor * channels, channels, conv1x1['wdt'], stride=conv1x1['str'], padding=conv1x1['pad'], dilation=conv1x1['dil'])),\n",
    "            #('norm_2', nn.InstanceNorm1d(channels)),\n",
    "            ('relu_2', nn.ReLU()),\n",
    "            ('conv1xd_2', nn.Conv1d(channels, channels, conv1xk['wdt'], stride=conv1xk['str'], padding=conv1xk['pad']*dilation, dilation=dilation)), \n",
    "            #('norm_3', nn.InstanceNorm1d(channels)),\n",
    "            ('relu_3', nn.ReLU()),\n",
    "            ('conv1x1_3', nn.Conv1d(channels, channel_factor * channels, conv1x1['wdt'], stride=conv1x1['str'], padding=conv1x1['pad'], dilation=conv1x1['dil']))\n",
    "         ]))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if self.type != 'enc':\n",
    "            c_out, c_in, wdt = self.resblock._modules['conv1xd_2'].weight.data.size()\n",
    "            self.resblock._modules['conv1xd_2'].weight.data[:,:,wdt//2+1:wdt] = torch.nn.Parameter(torch.zeros(c_out, c_in, wdt-wdt//2-1, device=device))\n",
    "        \n",
    "        if LOGGING:\n",
    "            print('def ResBlock::forward(self, input)', file=LOG)\n",
    "            print(input.size(), file=LOG)\n",
    "            print(step1.size(), file=LOG)\n",
    "            print(step2.size(), file=LOG)\n",
    "            print(step3.size(), file=LOG, end='\\n')\n",
    "        \n",
    "        output = self.resblock(input)\n",
    "        return output + input\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_dim, channels, res_sets, res_blocks, type):\n",
    "        super(CNN, self).__init__()\n",
    "        channel_factor = 2 if type != 'enc' else 1\n",
    "        self.type = type\n",
    "        self.embed = nn.Embedding(input_dim, channels)\n",
    "        self.channels = channels\n",
    "\n",
    "        layers = OrderedDict()\n",
    "        for res_set in range(res_sets):\n",
    "            for res_block in range(res_blocks):\n",
    "                layers['res_set_' + str(res_set) + '|res_block_' + str(res_block)] = ResBlock(channels, 2 ** res_block, type)\n",
    "\n",
    "        layers['fin|conv1x1'] = nn.Conv1d(channel_factor * channels, channels, conv1x1['wdt'], stride=conv1x1['str'], padding=conv1x1['pad'], dilation=conv1x1['dil'])\n",
    "        layers['fin|ReLU'] = nn.ReLU()\n",
    "        if type != 'enc':\n",
    "            layers['fin|conv1xd'] = nn.Conv1d(channels, n_letters, conv1xk['wdt'], stride=conv1xk['str'], padding=conv1xk['pad'])\n",
    "            layers['fin|logsoftmax'] = nn.LogSoftmax(dim=1)\n",
    "        self.CNN = nn.Sequential(layers)\n",
    "\n",
    "    def forward(self, source=None, target=None, encoder_output=None):\n",
    "        #print('In forward():')\n",
    "        if self.type == 'enc':\n",
    "            if LOGGING:\n",
    "                print('def CNN::forward(self, source, target, encoder_output) self.type == enc', file=LOG)\n",
    "                print('source', file=LOG)\n",
    "                print(source.size(), file=LOG, end='\\n')\n",
    "                #print(source, file=LOG)\n",
    "            \n",
    "            tmp = self.embed(source)\n",
    "            emb = torch.transpose(tmp, 1, 2)\n",
    "        else:\n",
    "            if LOGGING:\n",
    "                print('def CNN::forward(self, source, target, encoder_output) self.type == dec', file=LOG)\n",
    "                print('target', file=LOG)\n",
    "                print(target.size(), file=LOG)\n",
    "                #print(target, file=LOG)\n",
    "                print('encoder_output', file=LOG)\n",
    "                print(encoder_output.size(), file=LOG)\n",
    "                #print(encoder_output, file=LOG)\n",
    "            \n",
    "            tmp = self.embed(target)\n",
    "            tmp2 = torch.transpose(tmp, 1, 2)\n",
    "            \n",
    "            if LOGGING:\n",
    "                print('embedding of the target', file=LOG)\n",
    "                print(tmp2.size(), file=LOG, end='\\n')\n",
    "                #print(tmp2)\n",
    "            \n",
    "            emb = torch.zeros(tmp2.size(0), 2 * tmp2.size(1), tmp2.size(2), device=device)\n",
    "            emb[:,:self.channels,:] = tmp2\n",
    "            for char in range(min(tmp2.size(2), encoder_output.size(2))):\n",
    "                emb[:,self.channels:2*self.channels,char] = encoder_output[:,:,char]\n",
    "\n",
    "            c_out, c_in, wdt = self.CNN._modules['fin|conv1xd'].weight.data.size()\n",
    "            self.CNN._modules['fin|conv1xd'].weight.data[:,:,wdt//2+1:wdt] = torch.nn.Parameter(torch.zeros(c_out, c_in, wdt-wdt//2-1, device=device))\n",
    "        return self.CNN(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q2WE1IAtx2sx"
   },
   "outputs": [],
   "source": [
    "################\n",
    "### TRAINING ###\n",
    "################\n",
    "\n",
    "# TIMING [COPY-PASTED FROM THE PYTORCH TUTORIAL]\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(s / percent - s))\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "EMBED_DIM = 20\n",
    "\n",
    "# Constants from the paper.\n",
    "\n",
    "ADAM_LEARNING_RATE = 0.0003\n",
    "RES_SETS = 6        # Number of sets of residual blocks\n",
    "RES_BLOCKS = 5      # Number of residual blocks per set\n",
    "\n",
    "# Define 1 GD step. W/o Teacher Forcing\n",
    "def train_no_TF(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    target_length = target_tensor.size(1)\n",
    "\n",
    "    encoder_output = encoder(source=input_tensor)\n",
    "\n",
    "    output = torch.zeros(target_tensor.size(0), target_length, dtype=torch.int64, device=device, requires_grad=False)\n",
    "    for i in range(target_tensor.size(0)):\n",
    "        output[i][0] = letterToIndex(SOS_token)\n",
    "    loss = 0\n",
    "\n",
    "    for char_index in range(1, target_length):\n",
    "        decoder_output = decoder(target=output[:,:char_index], encoder_output=encoder_output[:,:,:char_index])\n",
    "        loss_per_char = criterion(decoder_output[:,:,char_index-1], target_tensor[:,char_index-1])\n",
    "        loss += loss_per_char.detach()\n",
    "\n",
    "        if LOGGING:\n",
    "            print('In def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)', file=LOG)\n",
    "            print('char_index = %d' % char_index, file=LOG)\n",
    "            print(output.size(), file=LOG)\n",
    "            print(decoder_output.size(), file=LOG)\n",
    "\n",
    "        loss_per_char.backward(retain_graph=True)\n",
    "        output[:,char_index] = torch.tensor(np.argmax(decoder_output[:,:,char_index-1].detach().numpy(), axis=1))\n",
    "                               \n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.detach() / target_length\n",
    "\n",
    "# Define 1 GD step. W/ Teacher Forcing\n",
    "def train_TF(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    target_length = target_tensor.size(1)\n",
    "\n",
    "    encoder_output = encoder(source=input_tensor)\n",
    "    decoder_output = decoder(target=target_tensor, encoder_output=encoder_output) # Teacher forcing\n",
    "\n",
    "    loss = criterion(decoder_output, target_tensor)\n",
    "\n",
    "    if LOGGING:\n",
    "        print('In def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)', file=LOG)\n",
    "        print('char_index = %d' % char_index, file=LOG)\n",
    "        print(encoder_output.size(), file=LOG)\n",
    "        print(decoder_output.size(), file=LOG)\n",
    "\n",
    "    loss.backward()                               \n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.detach() \n",
    "\n",
    "# Define the actual training.\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, save_every=10000):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    start_iter = START_ITER\n",
    "\n",
    "    # Choose whether to use teacher forcing or not.\n",
    "    train = lambda it, tt, e, d, eo, do, c: train_TF(it, tt, e, d, eo, do, c) if TEACHER_FORCING else train_no_TF(it, tt, e, d, eo, do, c)\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), ADAM_LEARNING_RATE)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), ADAM_LEARNING_RATE)\n",
    "\n",
    "    if LOAD_MODEL_FROM_FILE:\n",
    "        checkpoint = torch.load(PATH + 'bytenet.train.tar', map_location=device)\n",
    "        start_iter = checkpoint['iter']\n",
    "        encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "        decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "        encoder_optimizer.load_state_dict(checkpoint['encoder_optimizer_state_dict'])\n",
    "        decoder_optimizer.load_state_dict(checkpoint['decoder_optimizer_state_dict'])\n",
    "\n",
    "        encoder.to(device)\n",
    "        decoder.to(device)\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        print('Loaded the model from %sbytenet.train.tar, which has already been trained for %d iterations.' % (PATH, start_iter))\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(start_iter + 1, start_iter + n_iters + 1):    \n",
    "        input_tensor, target_tensor = bucketised_batches[iter % len(bucketised_batches)]\n",
    "        if LOGGING:\n",
    "            print('def trainIters(encoder, decoder, n_iters, print_every, plot_every, save_every, learning_rate)', file=LOG)\n",
    "            print('iter = %d' % iter, file=LOG)\n",
    "            print(input_tensor.size(), file=LOG)\n",
    "            print(target_tensor.size(), file=LOG, end='\\n')\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            real_iter = iter - start_iter\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, real_iter / n_iters), iter, real_iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "        if iter % save_every == 0:\n",
    "            torch.save({\n",
    "                'iter': iter,\n",
    "                'encoder_state_dict': encoder.state_dict(),\n",
    "                'decoder_state_dict': decoder.state_dict(),\n",
    "                'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "                'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "            }, PATH + 'bytenet.train.tar')\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ci0NXsmgyBtB",
    "outputId": "30d27c2d-b48d-46f2-e001-2d46adea66cc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np \n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "encoder = CNN(n_letters, EMBED_DIM, RES_SETS, RES_BLOCKS, 'enc').to(device)\n",
    "decoder = CNN(n_letters, EMBED_DIM, RES_SETS, RES_BLOCKS, 'dec').to(device)\n",
    "\n",
    "trainIters(encoder, decoder, 1000000, print_every=10, plot_every=100, save_every=50)\n",
    "\n",
    "LOG.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in encoder.parameters()) + sum(p.numel() for p in decoder.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3-HZ5746qBD"
   },
   "outputs": [],
   "source": [
    "##################\n",
    "### EVALUATION ###\n",
    "##################\n",
    "\n",
    "# TIMING [COPY-PASTED FROM THE PYTORCH TUTORIAL]\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(s / percent - s))\n",
    "\n",
    "# EVALUATE\n",
    "\n",
    "EMBED_DIM = 20\n",
    "RES_SETS = 6        # Number of sets of residual blocks\n",
    "RES_BLOCKS = 5      # Number of residual blocks per set\n",
    "\n",
    "# Evaluate on 1 batch.\n",
    "def evaluate(input_tensor, target_tensor, encoder, decoder, criterion):\n",
    "    target_length = target_tensor.size(1)\n",
    "        \n",
    "    encoder_output = encoder(source=input_tensor)\n",
    "\n",
    "    output = torch.zeros(target_tensor.size(0), target_length, dtype=torch.int64, device=device, requires_grad=False)\n",
    "    for i in range(target_tensor.size(0)):\n",
    "        output[i][0] = letterToIndex(SOS_token)\n",
    "    loss = 0\n",
    "\n",
    "    for char_index in range(1, target_length):\n",
    "        decoder_output = decoder(target=output[:,:char_index], encoder_output=encoder_output[:,:,:char_index])\n",
    "        loss += criterion(decoder_output[:,:,char_index-1], target_tensor[:,char_index-1]).detach()\n",
    "        output[:,char_index] = torch.tensor(np.argmax(decoder_output[:,:,char_index-1].detach().numpy(), axis=1))\n",
    "\n",
    "    return loss.detach() / target_length\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on all batches.\n",
    "def evaluateIters(encoder, decoder, print_every = 10):\n",
    "    print_loss_total = 0\n",
    "    num_of_pairs = 0\n",
    "    checkpoint = torch.load(PATH + 'bytenet.eval.tar', map_location=device)\n",
    "    start_iter = checkpoint['iter']\n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    print('Loaded the model from %sbytenet.eval.tar, which has already been trained for %d iterations.' % (PATH, start_iter))\n",
    "\n",
    "    criterion = nn.NLLLoss(reduction='sum')\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for batch, (input_tensor, target_tensor) in enumerate(bucketised_batches):\n",
    "        loss = evaluate(input_tensor, target_tensor, encoder, decoder, criterion)\n",
    "        print_loss_total += loss\n",
    "        num_of_pairs += input_tensor.size(0)\n",
    "\n",
    "        if batch % print_every == 0:\n",
    "            print('%s (%d %d%%) %d pairs processed so far' % (timeSince(start, num_of_pairs / DS_SIZE), batch, batch / len(bucketised_batches) * 100, num_of_pairs))\n",
    "            \n",
    "    return print_loss_total, num_of_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 527313,
     "status": "ok",
     "timestamp": 1588032063925,
     "user": {
      "displayName": "Igor Nikitin",
      "photoUrl": "",
      "userId": "06006776301613262626"
     },
     "user_tz": -60
    },
    "id": "um3horcMB-vm",
    "outputId": "6fddbb20-85c4-4bec-a598-537bfc85a08d"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoder = CNN(n_letters, EMBED_DIM, RES_SETS, RES_BLOCKS, 'enc').to(device)\n",
    "    decoder = CNN(n_letters, EMBED_DIM, RES_SETS, RES_BLOCKS, 'dec').to(device)\n",
    "\n",
    "\n",
    "    print_loss_total, num_of_pairs = evaluateIters(encoder, decoder, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 770,
     "status": "error",
     "timestamp": 1588032136369,
     "user": {
      "displayName": "Igor Nikitin",
      "photoUrl": "",
      "userId": "06006776301613262626"
     },
     "user_tz": -60
    },
    "id": "_iyqmr-IFwfn",
    "outputId": "2e0c2aa3-928b-4a78-c416-08bab9122d06"
   },
   "outputs": [],
   "source": [
    "print(print_loss_total)\n",
    "print(num_of_pairs)\n",
    "print(print_loss_total / num_of_pairs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AML Training v2 (DS1k).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
